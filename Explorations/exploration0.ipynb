{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data engineering / Data science**\n",
    "Data engineering and data science are two complementary fields in machine learning, with data engineering focused on building and maintaining the data infrastructure, and data science focused on designing and building the machine learning models.\n",
    "\n",
    "Data engineering is the practice of building, maintaining, and scaling the infrastructure, tools, and processes required to store, process, and analyze large volumes of data. \n",
    "\n",
    "Data science is the practice of using statistical methods, machine learning algorithms, and other data analysis techniques to extract insights and make predictions from data. Data scientists are responsible for designing and building the machine learning models, selecting appropriate algorithms, and evaluating the model's performance. \n",
    "\n",
    "Both fields are critical for the success of machine learning projects.\n",
    "\n",
    "### **Batch Processing**\n",
    "Batch processing refers to the process of training a model on a batch of data, rather than individual samples.\n",
    "In batch processing, the model is trained on a fixed-sized subset of training data at a time.\n",
    "\n",
    "The goal of batch processing is to provide a compromise between the computational efficiency of training on large datasets and the ability to update the model with new information from the data.\n",
    "\n",
    "During each iteration of the training process, the model’s parameters are updated based on the error it made on the batch of data. Repeat the process. Common in deep learning.\n",
    "\n",
    "### **Real-Time Processing**\n",
    "Real-time processing is important in many applications, such as robotics, autonomous vehicles, streaming data analysis and financial trading, where quick and accurate predictions are critical to the system’s operation. Real-time processing is often combined with online learning, where the model can be updated with new data as it arrives, so that it can continuously adapt and improve over time.\n",
    "\n",
    "### **CAP Theorem**\n",
    "The CAP Theorem is not a formal proof, but rather a theoretical observation. It states that it is impossible for a system to simultaneously provide all three guarantees:\n",
    "\n",
    "1. Consistency: All nodes in the system see the same data at the same time.\n",
    "\n",
    "2. Availability: Every request to the system receives a response, without guarantee that it contains the most recent version of the data.\n",
    "\n",
    "3. Partition tolerance: The system continues to function even when network partition occur, meaning that communication between nodes is lost or delayed.\n",
    "\n",
    "\n",
    "### **ETL / ELT**\n",
    "\n",
    "ETL (Extract, Transform, Load) and ELT (Extract, Load, Transform) are processes used in data integration and management to move data from one or more sources to a destination for analysis and reporting.\n",
    "\n",
    "The choice between ETL and ELT depends on the specific requirements of the data integration and management solution, as well as the capabilities of the target system. ELT is well suited for organizations with large amounts of data and advanced analytics needs, while ETL is still widely used for simpler data integration and management tasks.\n",
    "\n",
    "### **Distributed systems**\n",
    "In a distributed machine learning system, data is typically divided into smaller pieces and distributed across multiple nodes, where it can be processed in parallel. The results of the processing are then combined to produce a single result. This type of distributed computation can greatly speed up the training of machine learning models, especially for large and complex models.\n",
    "\n",
    "7. API\n",
    "8. Load Balancer\n",
    "9. Model Deployment\n",
    "10. Model Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Typer av AI\n",
    "\n",
    "2. bias, varians, overfit samt underfit\n",
    "\n",
    "3. Algoritmer inom supervised learning som ex \n",
    "    - linjär regression\n",
    "    - beslutsträd\n",
    "    - random forest\n",
    "<br><br>\n",
    "4. Algoritmer inom unsupervised learning som ex\n",
    "    - klustring\n",
    "    - logistisk regresison\n",
    "    - SVM\n",
    "    - DBSCAN\n",
    "    - AI metoder baserade på beslutsträd och random forest algoritmer\n",
    "<br><br>\n",
    "5. Grunderna i artificiella neurala nätverk, gradient descent och loss-funktioner\n",
    "\n",
    "6. Problemmodellering och problemlösning inom AI\n",
    "\n",
    "7. Dimensionsreduceringstekniker som ex PCA\n",
    "\n",
    "8. Utföra en lämplig datauppdelning, “data shuffling” samt undvika “data leakage”\n",
    "\n",
    "9. Träna färdigimplementerade maskininlärningsalgoritmer och tolka “loss-kurvor”\n",
    "\n",
    "10. Utföra inferens med ny data givet en färdigtränad modell\n",
    "\n",
    "11. Utföra en enklare evaluering av maskininlärningsmodeller\n",
    "\n",
    "12. Utföra enklare dimensionsreduceringstekniker\n",
    "\n",
    "13. Självständigt kunna utföra en enkel förbehandling av data, träna en maskininlärningsmodell samt använda modellen för inferens\n",
    "\n",
    "14. Självständigt kunna utföra en enklare evaluering av resultat samt jämföra olika tekniker och modeller"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train | test split: cross validation\n",
    "\n",
    "MAE\n",
    "\n",
    "MSE\n",
    "\n",
    "RMSE\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Week #1*\n",
    "\n",
    "Regression Linear, Polynomial, Grandient Descent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Regression Linear*\n",
    "\n",
    "\n",
    "Simple linear regression<h2>\n",
    "$\\bar{y} = \\beta_0 + \\beta_1 \\mathbf{x_1} + \\epsilon$\n",
    "</h2>\n",
    "\n",
    "responese, dependent, prediction -- predictor variable, independent variable, feature\n",
    "RSS, residual sum of square\n",
    "OLS, ordinary list square"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITHS-AI22-ML-sqO3erDD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44bf4f2bb6af3eac852fbf2397258e4d896c3822e6fae76a2c7f7646848325d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
