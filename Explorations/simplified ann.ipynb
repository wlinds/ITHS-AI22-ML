{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons\n",
    "\n",
    "<div style=\"display: flex; flex-direction: row;\">\n",
    "        <div style=\"flex: 3; padding: 20px; margin: 10px\">\n",
    "\n",
    "- A perceptron takes several binary inputs, $x_1$, $x_2$, ... and produces a single binary output.\n",
    "\n",
    "- <a href=\"https://en.wikipedia.org/wiki/Frank_Rosenblatt\">Frank Rosenblatt</a> introduced *weights*, real numbers expressing the importance of the inputs.\n",
    "\n",
    "- The neuron's output, 0 or 1, is determined by whether the weighted sum \n",
    "$\\sum_jw_jx_j$ is less than or greater than some threshold value ($b$). \n",
    "\n",
    "\n",
    "</div>\n",
    "        <div style=\"flex: 1.5; background-color: #f6f6f6; border-radius: 20px; padding: 20px; margin: 10px\">\n",
    "        <img src=\"http://neuralnetworksanddeeplearning.com/images/tikz0.png\"><br>\n",
    "        <div style=\"text-align: right\"><a href=\"http://neuralnetworksanddeeplearning.com/chap1.html\">source</a></div>\n",
    "        </div>\n",
    "</div>\n",
    "\n",
    "## Briefly about logical gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND gate returns True only when its input are True.\n",
    "def and_gate(a, b):\n",
    "    if a == True and b == True:\n",
    "          return True\n",
    "    else: return False\n",
    "\n",
    "# NAND gate returns False only when its inputs are True.\n",
    "# In other words, a NAND gate is the negation of an AND gate.\n",
    "def nand_gate(a, b):\n",
    "    if a == True and b == True:\n",
    "          return False\n",
    "    else: return True\n",
    "\n",
    "# XOR gate returns True only when its inputs are different.\n",
    "def xor_gate(a, b):\n",
    "    if a != b:\n",
    "          return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nand_gate(0, 1)=True, xor_gate(0,1)=True\n",
      "nand_gate(0, 0)=True, xor_gate(0,0)=False\n"
     ]
    }
   ],
   "source": [
    "print(f'{nand_gate(0, 1)=}, {xor_gate(0,1)=}')\n",
    "print(f'{nand_gate(0, 0)=}, {xor_gate(0,0)=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a perceptron with two inputs, each with weight âˆ’2 and an overall bias of 3:<br>\n",
    "<div style=\"display: flex; flex-direction: row;\">\n",
    "<div style=\"flex: 1.5; background-color: #f6f6f6; padding: 20px; margin: 10px; border-radius:20px;\">\n",
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz2.png\"><br>\n",
    "<div style=\"text-align: right\"><a href=\"http://neuralnetworksanddeeplearning.com/chap1.html\">source</a></div>\n",
    "</div>\n",
    "<div style=\"flex: 3; padding: 20px; margin: 10px\">\n",
    "\n",
    "We see that input 0 0 produces ouput 1, since:\n",
    "\n",
    "<code>(-2) * 0 + (-2) * 0 + 3 = 3</code> is positive. \n",
    "\n",
    "While input 1 1 produces output -1, since:\n",
    "\n",
    "<code>(-2) * 1 + (-2) * 1 + 3 = -1</code> is negative.\n",
    "\n",
    "And so our perceptron implements a NAND gate!\n",
    "\n",
    "</div></div>\n",
    "\n",
    "We can use networks of perceptrons to compute any logical function.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Creating a simplified (broken) ANN\n",
    "\n",
    "Let's say we want to create a neural network that classifies if a customer will buy a product based on their age and income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "# Generate pre-engineered synthetic data\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, n_classes=2, random_state=42)\n",
    "\n",
    "data = pd.DataFrame(X, columns=['age', 'income'])\n",
    "data['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.999102</td>\n",
       "      <td>-0.663860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.246686</td>\n",
       "      <td>1.153597</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.962777</td>\n",
       "      <td>0.859397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.957441</td>\n",
       "      <td>2.033645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.141165</td>\n",
       "      <td>1.059449</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    income  target\n",
       "0 -0.999102 -0.663860       1\n",
       "1  1.246686  1.153597       1\n",
       "2  0.962777  0.859397       1\n",
       "3 -2.957441  2.033645       1\n",
       "4  1.141165  1.059449       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the sigmoid activation function and a neural network with one hidden layer and two neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 15:27:08.036499: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential     # Linear stack of layers\n",
    "from keras.layers import Dense          # Dense layer for fully connected layers\n",
    "\n",
    "# Feedforward neural network\n",
    "model = Sequential()\n",
    "\n",
    "# Add a Dense layer with 2 output units and sigmoid activation function to represent the hidden layer\n",
    "model.add(Dense(2, input_dim=2, activation='sigmoid'))\n",
    "\n",
    "# Add another Dense layer with 1 output unit and sigmoid activation function to represent the output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Cross-entropy loss function: measures the performance of the model\n",
    "# Adam optimizer: updates the weights and accuracy metric to evaluate the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model using the fit() method in Keras, and use a validation split of 20% to monitor the performance of the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# history = model.fit(X, y, epochs=10, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase epochs\n",
    "history = model.fit(X, y, epochs=100, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3477 - accuracy: 0.8680\n",
      "Accuracy: 86.80%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the model on the test set\n",
    "score = model.evaluate(X, y, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (score[1]*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune the hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define the neural network architecture with new hyperparameters\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=2, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the model with more epochs\n",
    "history = model.fit(X, y, epochs=500, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = make_classification(n_samples=10, n_features=2, n_informative=2, n_redundant=0, n_classes=2, random_state=42)\n",
    "\n",
    "# Create a pandas dataframe from the data\n",
    "test_data = pd.DataFrame(X_test, columns=['age', 'income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        age    income\n",
       " 0  1.068339 -0.970073\n",
       " 1 -1.140215 -0.838792\n",
       " 2 -2.895397  1.976862\n",
       " 3 -0.720634 -0.960593\n",
       " 4 -1.962874 -0.992251\n",
       " 5 -0.938205 -0.543048\n",
       " 6  1.727259 -1.185827\n",
       " 7  1.777367  1.511576\n",
       " 8  1.899693  0.834445\n",
       " 9 -0.587231 -1.971718,\n",
       " array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.07173289],\n",
       "       [0.20864128],\n",
       "       [0.955787  ],\n",
       "       [0.1380484 ],\n",
       "       [0.22591664],\n",
       "       [0.32604253],\n",
       "       [0.04844391],\n",
       "       [0.952324  ],\n",
       "       [0.9014092 ],\n",
       "       [0.03739632]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITHS-AI22-ML-sqO3erDD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
