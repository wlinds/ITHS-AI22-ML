{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree\n",
    "\n",
    "-> regression tree\n",
    "\n",
    "-> classification tree\n",
    "\n",
    "CART = Classification & Regression Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tree building process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem med decision trees vad gäller prediction, för att förbättra prediktionsförmåga -> kombinera flera decision trees\n",
    "\n",
    "Bootstrap aggregation (bagging)\n",
    " -> minska varians genom att ha fler träningsset\n",
    "\n",
    " Z_1 -> Z_N har $\\sigma^2$ i varians\n",
    "\n",
    " var(Z) = varians av (Z1,Z2,Z3... / n)\n",
    " Eftersom n är en konstant = 1/ $n^2$\n",
    "\n",
    "\n",
    "Bryt ut 1 genom n^2\n",
    "\n",
    "var(z_1) + var(z_2) ... var(z_n)\n",
    "\n",
    "= $\\sigma^2$ / n\n",
    "\n",
    "fler träningsset => lägre varians"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- problem: har ej fler dataset\n",
    "- -> sampla från samma dataset flera gånger \n",
    "- => bootstrapping\n",
    "\n",
    "Flera olika träningsset => träd => minska varians"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging\n",
    "- generera B bootstrapped träningsset\n",
    "\n",
    "prediction (regression)\n",
    "<h2>\n",
    "\n",
    "$\\hat{f}_{bag}(x) = $\n",
    "\n",
    "$\\frac{1}{B}\\sum^B\\hat{f}^{*b}(x)$\n",
    "\n",
    "</h2>\n",
    "\n",
    "Går även att använda bagging för linjär regression."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Går även att använda bagging för linjär regression."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest\n",
    "\n",
    "- bygga decision trees på bootstrap samples\n",
    "- -> $\\forall$ split i träden gör vi ett slumpmässigt val av $m$ predictors av alla predictors, baserat på dessa kolla vilken som minskar RSS mest\n",
    "\n",
    "Recursive binary splitting för att minimera \n",
    "\n",
    "m ≈ $\\sqrt{p}$, där $p$ är predictors "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Dataset:\n",
    "b_1 -> träd  \\\n",
    "b_2 -> träd   \\  \n",
    ".              } aggregering\n",
    ".             /\n",
    "b_n -> träd  /\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITHS-AI22-ML-sqO3erDD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
